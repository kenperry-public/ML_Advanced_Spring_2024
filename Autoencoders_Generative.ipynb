{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
    "\\def\\qr#1{\\mathcal{q}(#1)}\n",
    "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "An *Autoencoder* (AE) is a Neural Network comprised of two parts:\n",
    "- an *Encoder*, which takes the input $\\x$ and produces an intermediate (\"latent\") representation $\\z$ as output\n",
    "- a *Decoder*, which takes $\\z$ as input and attempts to reproduce $\\x$ as output\n",
    "\n",
    "Both the Encoder and Decoder are Neural Networks\n",
    "- their weights are learned by training them in tandem\n",
    "- on training set $\\langle \\X, \\y \\rangle = \\langle \\X, \\X \\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_vanilla.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A non-trivial Autoencoder (i.e., one in which the parts are not merely the Identity transformation)\n",
    "- has latent representation $\\z$ of dimension less than input $\\x$\n",
    "- $\\z$ is a *bottle-neck*\n",
    "- forcing dimensionality reduction, like PCA\n",
    "- causing the inversion of the Decoder to be imperfect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Comparison of Autoencoders and PCA\n",
    "\n",
    "Both the AE and PCA are methods to create representations of an input of length $n$\n",
    "via reduced dimensionality vectors of length $r \\le n$\n",
    "\n",
    "They are similar in *purpose* but different in *detail*\n",
    "- PCA creates $n$ vectors (of length $n$) called *components*\n",
    "    - Each $\\x^\\ip$ of length $n$ is represented as a linear combination of $r \\le n$ components\n",
    "        - The reduced dimensionality representation is a vector of length $r \\le n$: the weights used in the linear combination\n",
    "    - The components are common to all inputs $\\x^\\ip$\n",
    "- Autoencoder\n",
    "    - the reduced dimensionality representation is a vector of length $r \\le n$\n",
    "    - the representation is unique to $\\x^\\ip$: not shared \"components\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our interest in Autoencoders\n",
    "- Study Functional architecture\n",
    "    - [TensorFlow Tutorial on Autoencoders](https://www.tensorflow.org/tutorials/generative/autoencoder)\n",
    "- Generative\n",
    "    - Create *synthetic* examples $\\x'$\n",
    "    - By sampling $\\z'$ from the space of latent representations\n",
    "    - And inverting them\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Generator</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_decoder.jpg\" width=80%</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uses\n",
    "\n",
    "As an aside, we mention other use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dimensionality reduction and Transfer learning\n",
    "\n",
    "Once the Autoencoder has been trained, we can discard the Decoder\n",
    "- Use the Encoder to create reduced dimension representations of large and high dimension inputs\n",
    "    - Image search by replacing 3D megapixel images by shorter, 1D vectors\n",
    "- Transfer to another task\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder: Encoder + New head</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_encoder_new_head.jpg\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## De-noising Autoencoder\n",
    "\n",
    "Using an AE for dimensionality reduction is similar to using PCA\n",
    "- **But** unlike PCA, there is no **explicit** \"relative importance\" associated with the retained dimensions\n",
    "\n",
    "But we can *hope*that the information lost through the bottleneck process is less important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A *De-noising Autoencoder* is an Autoencoder trained on a slightly corrupted \"noisy\" input\n",
    "- $\\langle \\X, \\y \\rangle = \\langle \\X + \\epsilon, \\X \\rangle$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder: Denoising</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_denoising.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "De-noising may be useful as a pre-processing step for cleaning noisy data.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "            <th><center>De-noising autoencoder: noisy inputs, de-noised outputs</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/intro_autoencoder_result.png?raw=1\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Autoencoder as Anomaly Detector\n",
    "\n",
    "By forcing the input $\\x$ through a bottleneck, the reconstructed input hopefully has \"less important\" information stripped away.\n",
    "\n",
    "We may choose to characterize this lost information as an *anomaly* if the magnitude of the reconstruction error is larger than some threshold.\n",
    "- Error: noise to be removed\n",
    "- Signal: something unusual to be flagged for attention\n",
    "- Signal: a source of alpha\n",
    "    - Reconstructed input is our \"model\"'s prediction\n",
    "    - The noise is divergence from out model\n",
    "        - trading opportunity ?\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "            <th>Anomaly Detector</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/autoencoder_anomaly_normal.png\" width=80%></td>\n",
    "        <td><img src=\"images/autoencoder_anomaly_anomalous.png\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <center><td><img src=\"images/autoencoder_anomaly_error.png\" width=100%></td></center>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Details\n",
    "\n",
    "**Notation summary**\n",
    "\n",
    "term | dimension &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | meaning \n",
    ":---|:---|:---\n",
    "$\\x$ | $n$ | Input\n",
    "$\\tilde\\x$ | $n$ | Output: reconstructed $\\x$\n",
    "$\\z$ | $n' << n$ | Latent representation\n",
    "$E$  | $\\mathbb{R}^n \\rightarrow \\mathbb{R}^{n'}$ | Encoder\n",
    "            | | $E(\\x) = \\z $\n",
    "$D$  | $\\mathbb{R}^{n'} \\rightarrow \\mathbb{R}^n$ | Decoder\n",
    "            | | $\\tilde\\x = D(\\z) $\n",
    "            | | $\\tilde\\x = D( E(\\x) )$\n",
    "            | | $\\tilde\\x \\approx \\x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "The obvious loss functions compare the original $\\x^\\ip$ and reconstructed $\\tilde\\x^\\ip$ feature by feature:\n",
    "\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "$$\n",
    "\\loss^\\ip = \\sum_{j=1}^{|\\x|} { (\\x^\\ip_j - \\tx^\\ip_j)^2 }\n",
    "$$\n",
    "\n",
    "### Binary Cross Entropy\n",
    "\n",
    "For the special case where *each* original feature is in the range $[0,1]$ (e.g., an image)\n",
    "\n",
    "$$\n",
    "\\loss^\\ip = \\sum_{j=1}^{|\\x|} {  \\left( \\x^\\ip_j    \\log(\\tx^\\ip_j) + ( 1 - \\x^\\ip_j ) \\log(1 - \\tx^\\ip_j) \\right) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Limitations\n",
    "\n",
    "We propose to create synthetic examples $\\x'$ by sampling $\\z$.\n",
    "\n",
    "Although the synthetic $\\x'$ created by this inversion seems appealing, there are some issues\n",
    "- Assuming we need labeled examples $\\langle \\x, \\y \\rangle$\n",
    "    - we have no control as to the class $\\y'$ of the synthetic $\\x'$\n",
    "- Our method of sampling $\\z$ is not dependent on the distribution of $\\z$\n",
    "    - In general, the distribution is unknown\n",
    "    - In particular, the sample may not be representative of any known (e.g., training) true example\n",
    "    - Even if we obtain $\\z$ by slight modification of a particular $\\x^\\ip$\n",
    "    > $\\z = E( \\x^\\ip) + \\epsilon$\n",
    "    \n",
    "    there is no guarantee as to to the label or fidelity of $\\x' = D(\\z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate, we\n",
    "- create an [autoencoder](autoencoder.ipynb) for MNIST fashion\n",
    "    - 10 classes\n",
    "    - Latent representation are vectors of length 64\n",
    "- obtain the latent representations for a set of test inputs\n",
    "- create a scatter plot of the latents\n",
    "    - using PCA to project the high dimensionality latents to 2D\n",
    "    \n",
    "<img src=\"images/autoencoder_latents.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see\n",
    "- the latents are not uniformly distributed\n",
    "- latents of particular classes (each class depicted with a unique color) form clusters\n",
    "\n",
    "We can illustrate the latter point via a separate plot of the latents for each class\n",
    "\n",
    "\n",
    "<img src=\"images/autoencoder_latents_by_target.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, sampling latents uniformly will not necessarily find a latent \"in the neighborhood\"\n",
    "- of any of the classes\n",
    "- of any particular class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can emphasize the latter point.\n",
    "\n",
    "Let's explore the neighborhood around a the latent representation of a single input\n",
    "- add random normal noise with varying increments of standard deviation\n",
    "\n",
    "We might expect to obtain images similar to the original.\n",
    "\n",
    "<img src=\"images/autoencoder_perturb_single_img.png\" width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see from the above, even moving in a small radius from the\n",
    "latent of the original does not guarantee a realistic decoded output.\n",
    "- So we can't generate a synthetic example of a particular class by a small perturbation of the latent from a genuine image of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we conduct an experiment in interpolating between the latents associated with 2 inputs.\n",
    "- interpolate between the latents and decode\n",
    "- first plot: 0% second \"end\" image; 100% first image\n",
    "- last plot: 100% second image; 0% first image\n",
    "\n",
    "<img src=\"images/autoencoder_interpolate_2_imgs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see from the intermediate outputs\n",
    "- not all latents correspond to recognizable classes\n",
    "\n",
    "Thus, we see issues associated with generating synthetic examples by\n",
    "simple-minded sampling of the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments with Autoencoders\n",
    "\n",
    "The plots in this notebook were generated by\n",
    "this [notebook](Autoencoder_practice.ipynb)\n",
    "- derived from the [TensorFlow tutorial on Autoencoders](https://www.tensorflow.org/tutorials/generative/autoencoder)\n",
    "- illustrates Latent representation, Denoising, Anomaly Detection\n",
    "- (secondary objective: study the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
