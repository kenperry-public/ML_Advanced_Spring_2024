{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "This notebook is meant to serve as a *quick reference* of key concepts/notations\n",
    "from the Intro course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notation\n",
    "\n",
    "To ensure that everyone is up to speed on notation, let's review\n",
    "- [the notation](ML_Notation.ipynb) that we used in the \"Classical Machine Learning\" part of the intro course.\n",
    "- [additional notation](Intro_to_Neural_Networks.ipynb) used in the \"Deep Learning\" part of the intro course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representations\n",
    "\n",
    "A path through a Neural Network can be viewed as a sequence of representation transformations\n",
    "- transforming *raw features* $\\y_{(0)} = \\x$\n",
    "- into *synthetic features* $\\ \\y_\\llp$\n",
    "    - varying with layer $1 \\le \\ll \\le (L-1)$\n",
    "- of increasing abstraction\n",
    "\n",
    "Thus, the output anywhere along the path is an *alternate representation* of the input\n",
    "\n",
    "<div>\n",
    "    <center><strong>Path through a Neural Network</strong></center>\n",
    "    <br>\n",
    "    <div>\n",
    "    <!-- edX: Original: <img src=\"images/NN_Layers.png\"> replace by EdX created image -->\n",
    "    <img src=\"images/W12_L1_NN_layers1920by1080.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Shallow features are less abstract: \"syntax\", \"surface\"\n",
    "\n",
    "Deeper features are more abstract: \"semantics\", \"concepts\"\n",
    "- We may even interpret the features as \"pattern matching\" regions or concepts in the raw feature space.\n",
    "\n",
    "For example, in a CNN\n",
    "- shallow features are primitive shapes\n",
    "- deeper features seem to recognize combinations of shallower features\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "        <center><strong>Input features detected by layer</strong></center>\n",
    "        <br>\n",
    "        <img src=\"images/ThreeLayers_W8_L2_Sl21.png\" width=20%>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><strong>Saliency Maps and Corresponding Patches<br>Single Layer 5 Feature Map<br>On 9 Maximally Activating Input images</strong></center>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/ZF_p4_118_row11_col1_mag.png\"></td>\n",
    "        <td><img src=\"images/ZF_p4_118_row11_col1_patch_mag.png\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=2><center>Layer 5 ? Feature Map (Row 11, col 1).</center></td>\n",
    "    </tr>\n",
    "</table>\n",
    "Attribution: https://arxiv.org/abs/1311.2901\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the simple architectures of the Intro course, we mostly ignored the intermediate representations\n",
    "$$\n",
    "\\y_\\llp : \\; 1 \\le \\ll \\le (L-1)\n",
    "$$\n",
    "\n",
    "The layers were referred to as \"hidden\" for a reason !\n",
    "\n",
    "We will discover uses for intermediate representations and show how to build a \"feature extractor\" to obtain them\n",
    "from a given architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "With a sequence $\\x^\\ip$ as input, and a sequence $\\y$ as a potential output,  the questions arises:\n",
    "- How does an RNN produce $\\y_\\tp$, the $t^{th}$ output ?\n",
    "\n",
    "Some choices\n",
    "- Predict $\\y_\\tp$ as a direct function of the prefix of $\\x$ of length $\\tt$: \n",
    "$$\\pr{\\y_\\tp | \\x_{(1)} \\dots \\x_\\tp} $$\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "    <center><strong>Direct function</strong></center>\n",
    "    <img src=\"images/RNN_arch_parallel.png\" width=50%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Loop\n",
    "    - Uses a \"latent state\" that is updated with each element of the sequence, then predict the output\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\pr{\\h_\\tp | \\x_\\tp, \\h_{(\\tt-1)} } & \\text{latent variable } \\h_\\tp \\text{encodes } [ \\x_{(1)} \\dots \\x_\\tp ]\\\\\n",
    "\\pr{\\y_\\tp | \\h_\\tp }              & \\text{prediction contingent on latent variable} \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "    \n",
    "<br>\n",
    "<div>\n",
    "    <center><strong>Loop with latent state</strong></center>\n",
    "    <img src=\"images/RNN_arch_loop.png\" width=70%>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Latent state\n",
    "\n",
    "The *latent state* $\\h_\\tp$ is a kind of memory that acts\n",
    "as a *summary* of the prefix of sequence $\\x$ through time step $\\tt%:\n",
    "\n",
    "$$\n",
    "\\h_\\tp = \\text{summary}(\\x_{([1:\\tt])})\n",
    "$$\n",
    "\n",
    "Note that $\\h_\\tp$ is a *vector* of fixed length.\n",
    "\n",
    "Thus, it is a *fixed length* representation of the key aspects\n",
    "of a sequence $\\x$ of potentially *unbounded* length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example**\n",
    "\n",
    "Let's use an RNN to compute the sum of a sequence numbers\n",
    "- the latent state $\\h_\\tp$ can be maintained as \n",
    "$$\n",
    "\\h_\\tp = \\text{summary}(\\x_{([1:\\tt])}) = \\sum_{\\tt' =1}^\\tt { \\x_{(\\tt')} }\n",
    "$$\n",
    "- by updating $\\h_\\tp$ in the loop\n",
    "$$\n",
    "\\h_\\tp = \\h_{(\\tt-1)} + \\x_\\tp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's make this concrete with an example: a sequence of words\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>RNN</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_loop_NLP.png\" width=1000></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\h_\\tp$ is a **fixed length** vector that \"summarizes\" the prefix of sequence $\\x$ up to element $\\tt$.\n",
    "\n",
    "The sequence is processed element by element, so order matters.\n",
    "\n",
    "\\begin{array} \\\\\n",
    "\\h_{(0)} & = & \\text{summary}( [ \\text{Machine} ]) \\\\\n",
    "\\h_{(1)} & = & \\text{summary}( [ \\text{Machine, Learning} ]) \\\\\n",
    "\\vdots \\\\\n",
    "\\h_\\tp & = & \\text{summary}( [ \\x_{(0)}, \\ldots \\x_\\tp ] ) \\\\\n",
    "\\vdots \\\\\n",
    "\\h_{(5)} & = & \\text{summary}( [ \\text{Machine, Learning, is, easy, not, hard} ]) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The importance of $\\h_\\tp$ being *fixed length*\n",
    "- can be used as input to other types of Neural Network layers\n",
    "- which *don't* process sequences.\n",
    "\n",
    "A typical example is a model for text classification (sentiment)\n",
    "- Using an RNN to create a fixed length encoding of a variable length sequence\n",
    "- A Head Layer that is a Binary Classifier\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center><strong>RNN Many to one; followed by classifier</strong></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_many_to_one_to_classifier.jpg\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Output $\\hat\\y_\\tp$ of an RNN\n",
    "\n",
    "According to our pseudo-code and diagram\n",
    "$$\n",
    "\\hat\\y_\\tp = \\h_\\tp\n",
    "$$\n",
    "\n",
    "That is: the output is the same as the latent state.\n",
    "\n",
    "It is easy to add another NN to transform $\\h_\\tp$ into a $\\hat\\y_\\tp$ that is different\n",
    "- we will omit this additional layer for clarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unrolled RNN diagram\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>RNN many to many API</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_layer_API_many_to_many.jpg\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoder-Decoder architecture; Auto-regressive \n",
    "\n",
    "A very common architecture pairs two RNN's\n",
    "- an Encoder, which summarizes the input sequence $\\x_{([1:\\bar T])}$ via final latent state $\\bar \\h_{(\\bar T)}$\n",
    "- a Decoder, which takes the input summary $\\bar \\h_{(\\bar T)}$ and outputs sequence $\\hat \\y_{([1:T])}$\n",
    "\n",
    "It is used for *Sequence to Sequence* tasks where both the input and output are sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center><strong>Encoder-Decoder for language translation</strong></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_layer_API_Encoder_Decoder_Language_Translation.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that the Decoder output $\\hat\\y_{(\\tt-1)}$ at position $(\\tt-1)$ is fed back as *input* for position $\\tt$.\n",
    "\n",
    "This is called *Autoregressive* behavior.\n",
    "\n",
    "It is typical behavior for Generative tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Test time: no forcing</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_layer_API_one_to_many.png\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models\n",
    "\n",
    "The *Language Model* training objective\n",
    "- given some text\n",
    "    - sequence of *tokens*\n",
    "- predict a word that could be the next word in the sequence\n",
    "\n",
    "We sometimes refer to this as the \"predict the next\" task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Clearly, we need to train a model on the \"predict the next\" objective with labeled examples.\n",
    "\n",
    "But this is sometimes called Semi-Supervised or Unsupervised because text is not inherently labeled.\n",
    "\n",
    "Yet we can easily create $T$ labeled examples from a text string $s[1:T]$. Example $\\tt$\n",
    "- feature: $s[1:\\tt-1]$\n",
    "- label: $s[\\tt]$\n",
    "\n",
    "<center>$\\mathbf{s} = \\mathbf{s}_{(1)}, \\ldots, \\mathbf{s}_{(T)}$</center>\n",
    "        <br><br><br>\n",
    "\\begin{array} \\\\\n",
    "      i  & \\x^\\ip  & \\y^\\ip \\\\\n",
    "      \\hline \\\\\n",
    "      1 & \\mathbf{s}_{(1) }  & \\mathbf{s}_{(2)} \\\\\n",
    "      2 & \\mathbf{s}_{(1), (2) }  & \\mathbf{s}_{(3)} \\\\\n",
    "      \\vdots \\\\\n",
    "      i & \\mathbf{s}_{(1), \\ldots, (i) }  & \\mathbf{s}_{(i+1)} \\\\\n",
    "      \\vdots \\\\\n",
    "      (T-1) & \\mathbf{s}_{(1), \\ldots, (T-1) }  & \\mathbf{s}_{(T)} \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The *Unsupervised Pre-Trained Model + Supervised Fine-Tuning paradigm*\n",
    "is \n",
    "- a way of adapting a model trained on the Language Modeling objective\n",
    "- to perform another task\n",
    "\n",
    "Pre-training refers to training a model on the Language Modeling objective with *lots* of data\n",
    "- this is called Unsupervised because text is not inherently labeled\n",
    "- we can easily create a labeled example  from a text string $s[1:T]$\n",
    "    - feature: $s[1:\\tt-1]$\n",
    "    - label: $s[\\tt]$\n",
    "\n",
    "- Pre-training\n",
    "    - Train a model with *lots* of data\n",
    "    - On the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
