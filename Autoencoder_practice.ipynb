{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Autoencoder: Code\n",
    "\n",
    "We discuss the highlights of the code in this [notebook](autoencoder.ipynb)\n",
    "- derived from the [Tensorflow tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deriving a new Model via sub-classing\n",
    "\n",
    "A Model object in Keras provides a consistent API to all sorts of models.\n",
    "\n",
    "This consistency makes is easier to deal to build, train, and use Neural Networks.\n",
    "\n",
    "For example, all Models provide methods\n",
    "- for `fit` and `predict`\n",
    "- as well as saving their architecture, weights, and training state\n",
    "    - can re-use a pre-trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our notebook we can [see a Basic Autoencoder](autoencoder.ipynb#First-example:-Basic-autoencoder)\n",
    "implemented as a sub-class of `Model`:\n",
    "    \n",
    "\n",
    "    latent_dim = 64 \n",
    "\n",
    "    class Autoencoder(Model):\n",
    "      def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(latent_dim, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "          layers.Dense(784, activation='sigmoid'),\n",
    "          layers.Reshape((28, 28))\n",
    "        ])\n",
    "\n",
    "      def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This example implements a simple architecture for the Encoder and Decoder\n",
    "- Encoder and Decoder don't need to be symmetric\n",
    "- Can be more complex\n",
    "\n",
    "<table>\n",
    "   <tr>\n",
    "            <th>Simple Autoencoder: Components</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/autoencoder_simple_encoder.png\" width=90%></td>\n",
    "        <td><img src=\"images/autoencoder_simple_decoder.png\" width=90%></td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Encoder (on the left)\n",
    "- flattens the 2D input image ($28 \\times 28$)\n",
    "- Uses a single `Dense` layer to create a latent vector of length `latent_dim`\n",
    "\n",
    "The Decoder (on the right)\n",
    "- takes a latent vector of length `latent_dim`\n",
    "- Uses a single `Dense` layer to create a (flattened 2D) 1D vector\n",
    "- Reshapes the 1D vector to a 2D image ($28 \\times 28$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `__init__` initialized method\n",
    "- creates each Neural Network sub-component\n",
    "- stores each as an attribute in the Model instance\n",
    "    - `self.encoder`: `Sequential` Model for Encoder\n",
    "    - `self.decoder`: `Sequential` Model for Decoder\n",
    "    \n",
    "So, an instance of an `Autoencoder` object *contains* two `Sequential` models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The heart of deriving a `Model` subclass is *overriding* the `call` method\n",
    "- When actual parameters are applied (via the parentheses operator) to an instance of the `Model` object (e.g., `m`)\n",
    "\n",
    "    `x = m(x)`\n",
    "- the `call` method is invoked\n",
    "\n",
    "In the case of the `Autoencoder`\n",
    "- the contained `encoder` and `decoder` models\n",
    "- are retrievied\n",
    "- and invoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Just a reminder as to why the Neural Network sub-components are\n",
    "- defined and saved in `__init__`\n",
    "- rather than instantiated in `call`\n",
    "\n",
    "By doing so in `__init__`\n",
    "- the `Autoencdoer` object has a *single* instance of each sub-component\n",
    "    - so the weights are preserved across `call`s\n",
    "    - for example: across mini-batches\n",
    "- had the objects been created in `call`\n",
    "    - they (and their weights) would disappear after the call ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can instantiate an instance of the `Autoencoder` `Model` object\n",
    "\n",
    "        autoencoder = Autoencoder(latent_dim) \n",
    "\n",
    "and then train it just like any other `Model` (e.g., `Sequential`)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "    \n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also apply all other `Model` methods like plotting its architecture\n",
    "\n",
    "    plot_model(autoencoder.encoder, \n",
    "               to_file=os.path.join(tempdir, \"autoencoder_simple_encoder.png\"), \n",
    "               show_shapes=True)\n",
    "\n",
    "and saving and restoring a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, we reference the contained sub-models (`encoder`, `decoder`)\n",
    "- and save them separately\n",
    "- as typically, they are used separately **after** training\n",
    "    - `encoder` is often used to create alternate (reduced dimension) representation of input\n",
    "    - `decoder` is often used to create synthetic examples (from latent \"noise\" input)\n",
    "\n",
    "\n",
    "    autoencoder.encoder.save(ae_encoder_dir)\n",
    "\n",
    "    autoencoder.decoder.save(ae_decoder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploring the latent space\n",
    "\n",
    "## Clustering\n",
    "\n",
    "The notebook [continues](autoencoder.ipynb#Examine-the-latent-representations-of-the-test-dataset)\n",
    "with code to examine the \"latent\" space\n",
    "- i.e., the output of the Encoder\n",
    "\n",
    "For example\n",
    "- we find the latent representation of each test example\n",
    "\n",
    "        encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "        \n",
    "and [plot](autoencoder.ipynb#Project-the-high-dimensionality-latents-into-2D) them to see whether the representations form clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since we can't easily visualize higher dimensional plots\n",
    "- we use Principal Components to for dimensionality reduction\n",
    "\n",
    "        pca = PCA_fit(encoded_imgs, n_components=10)\n",
    "        X_proj = pca.transform(encoded_imgs)\n",
    "\n",
    "- and plot the first two components\n",
    "- coloring each example according to its label (type of clothing)\n",
    "    - do examples of the same clothing type cluster ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Synthetic examples by altering a latent\n",
    "\n",
    "Once we observe that images of the same clothing type cluster in latent space\n",
    "- we might be able to create a new, synthetic image\n",
    "- by perturbing the latent representation of an example image\n",
    "- using the Decoder to translate the perturbed latent back into the space of Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We run [one experiment](autoencoder.ipynb#Explore-the-latents-in-a-small-radius-of-the-latent-of-a-single-input)\n",
    "- where we add random noise to a latent and Decode the result\n",
    "\n",
    "A [second experiment](autoencoder.ipynb#Interpolate-between-the-latents-of-two-inputs)\n",
    "examines whether there is a smooth transition between images of different clothing types\n",
    "- by interpolating (linear combination) of the latents of two Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We run a [third experiment](autoencoder.ipynb#Examine-the-2D-projections-obtained-by-PCA-on-the-high-dimensionality-latents)\n",
    "- trying to visualize the top Components of the PCA\n",
    "- an actual image is a linear combination of the components\n",
    "    - property of PCA\n",
    "    - do components have a \"natural\" interpretation ?\n",
    "        - expresses some commonality across multiple examples\n",
    "        - perhaps it expresses a \"concept\" (\"has arms\", \"has legs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Denoising Autoencoder\n",
    "\n",
    "We can also learn about the [Denoising Autoencoder](autoencoder.ipynb#Second-example:-Image-denoising).\n",
    "- using a simple `Dense` layer for the sub-components\n",
    "- using a more complex Convolutional (`Conv2d`) layer for the sub-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anomaly detection\n",
    "\n",
    "We [show](autoencoder.ipynb#Third-example:-Anomaly-detection) how to use an Autoencoder for Anomaly Detection.\n",
    "\n",
    "The basic idea is that the reduced dimension \"latent\" space is a *bottle-neck*\n",
    "- to minimize reconstruction error *over a wide variety of training examples*\n",
    "- the latent representation must focus on *commonality*\n",
    "    - properties that are *shared across several* training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By passing an example through the bottle-neck and reconstructing it (via the Decoder)\n",
    "- we \"strip away\" the non-essential properties of the example\n",
    "- Reconstruction error is the difference between the original and reconstructed output\n",
    "\n",
    "The theory is that an example with a *large Reconstruction Error*\n",
    "- is an *anomaly*\n",
    "- because it has a large element that is *not common* to many examples\n",
    "\n",
    "In the example: the anomaly corresponds to an abnormal heart rhythm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
