{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "\\newcommand{idxb}{\\mathbf{i}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using an LLM to improve prompts to an LLM\n",
    "\n",
    "**References**\n",
    "- [LLMs are Human-Level Prompt Engineers](https://arxiv.org/pdf/2211.01910.pdf)\n",
    "    - [APE summary](https://sites.google.com/view/automatic-prompt-engineer)\n",
    "    \n",
    "The Automatic Prompt Engineer (APE) is a system to *improve* upon prompts\n",
    "- given a prompt\n",
    "- APE will create a prompt that is *more effective*\n",
    "\n",
    "It uses an LLM for multiple purposes\n",
    "- to create variations of the given prompt\n",
    "- to evaluate which variation is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using APE to improve upon Instruction Following\n",
    "\n",
    "APE has been demonstrated to improve prompts **for a specific task** (not improvement of general prompts)\n",
    "\n",
    "The task is: creating *instructions*\n",
    "- to use in fine-tuning a raw LLM into an helpful Assistant\n",
    "- we described Instruction Following in the module [Synthetic data for Instruction Following](LLM_Instruction_Following_Synthetic_Data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to create an example of Instruction Following behavior we need a prompt with multiple parts\n",
    "- a textual *task description* (*instruction*) that describes a task to be performed\n",
    "- zero or more exemplars: demonstrating the input/output relationship described by the instruction\n",
    "\n",
    "Given just the exemplars (the second part)\n",
    "- we want APE to *create*  the \"best\" instruction (first part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The APE method for automatically generating \"good\" instructions is conceptually simple.\n",
    "\n",
    "As a first step, we get an LLM to generate plausible instructions.\n",
    "- Given the exemplars\n",
    "- Create a prompt\n",
    "- Whose \"response\" is an *instruction* that is a plausible description of the input/output relation in the exemplars\n",
    "\n",
    "We do this several times to generate multiple plausible instructions, conditional on the exemplars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a second step. we rank the multiple instruction candidates created in the first step.\n",
    "- we create a prompt requesting that the LLM *rank* the instructions created in the first step\n",
    "- we filter the instructions to the most highly ranked results\n",
    "\n",
    "As an optional third step, we can improve upon the *diversity* of the instructions selected in Step 2\n",
    "- create a prompt requesting that the LLM generate a *variation* of a selected instruction\n",
    "- Use an LLM to create a distribution of instruction, conditional on the exemplars\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a picture of the workflow.\n",
    "\n",
    "<table>\n",
    "    <center><strong>APE Workflow</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/ape_workflow.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2211.01910.pdf#page=2\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Step 1: LLM as Inference Model\n",
    "\n",
    "Goal: Get the LLM to create multiple *instruction* candidates, given the intended response\n",
    "- intended *response* are the exemplars demonstrating the input/output relation\n",
    "    - `Input: prove, Output: disprove`\n",
    "\n",
    "Given the context (response), the LLM is prompted to generate an *instruction* that could cause the given response\n",
    "- prompt is a Masked Language Modeling task: fill in the mask (`<INSERT>`)\n",
    "\n",
    "This is in the same spirit as [Backtranslation](LLM_Instruction_Following_Synthetic_Data.ipynb#Instruction-Backtranslation)\n",
    "- learns a new model to map from response to instruction\n",
    "- rather than adapting an LLM to do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Steps 2  and 3: LLM as Scoring Model\n",
    "\n",
    "Step 1 has created multiple possible instructions that are consistent with the exemplars.\n",
    "\n",
    "We wish to rank them.\n",
    "\n",
    "The ranking is performed by prompting the LLM to compute the likelihood\n",
    "- that a given response (an exemplar)\n",
    "        Input: direct, Output: indirect\n",
    "        \n",
    "- is consistent with each candidate instruction\n",
    "\n",
    "The candidate instructions are ranked from highest Likelihood to lowest.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Likelihood is expressed as the log probability\n",
    "- is a negative number since probabilities are fractions\n",
    "    - less negative numbers are higher probabilities\n",
    "- is the probability of the generated sequence\n",
    "    - product of the individual probabilities of the tokens in the sequence\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Steps 4  (Optional): LLM as Re-sampling model\n",
    "\n",
    "Here, we create multiple variants of a highly ranked instruction.\n",
    "\n",
    "Given the candidate Instruction selected by the previous step\n",
    "- generate a variation of the instruction\n",
    "- by asking the LLM to create it via text completion\n",
    "\n",
    "        Generate a variation of the following instruction ...\n",
    "        \n",
    "        Input: write the antonym of the word; Output: <COMPLETE>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each step is implemented as an instance of the pre-trained LLM's ability to complete text (or fill in a mask).\n",
    "\n",
    "No fine-tuning or adaptation of weights is involed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward/Reverse mode generation of candidates\n",
    "\n",
    "This is a minor technical point.\n",
    "\n",
    "The prompt in Step 1 of the  workflow above is not in the format consistent with text-continuation\n",
    "- format is called *forward generation*\n",
    "- so must use an LLM that solves Masked Language task, rather than text-continuation\n",
    "\n",
    "An alternate prompt can be used that is consistent with text-continuation\n",
    "- format is called *reverse generation*\n",
    "\n",
    "<table>\n",
    "    <center><strong>APE Forward/Reverse Generation templates</strong></center>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"images/ape_fwd_generation.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/ape_reverse_generation.png\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2211.01910.pdf#page=4\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# APE evaluation: super-human performance !\n",
    "\n",
    "Here is a comparison of APE generated prompts\n",
    "- versus\n",
    "    - an alternate method (previously published), labeled \"Greedy\"\n",
    "    - a human engineer (horizontal dotted line)\n",
    "- evaluated on models of various sizes\n",
    "    - GPT-3\n",
    "    - Instruct GPT-3 (fine-tuned for instruction following)\n",
    "- using 24 NLP tasks\n",
    "\n",
    "**Note**\n",
    "\n",
    "The reported statistic is *interquartile mean* (i.e., average after dropping the upper and lower 25% of results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>APE Workflow and Results</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/ape_results.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2211.01910.pdf#page=2\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zero-shot: Improving on \"Let's think step by step\"\n",
    "\n",
    "[Chain of Thought (CoT) prompting](NLP_Beyond_LLM.ipynb#Chain-of-thought-prompting)\n",
    "- is a simple technique\n",
    "- for create prompts with better performance\n",
    "- for multi-step reasoning problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the few-shot setting\n",
    "- exemplars demonstrate step by step reasoning\n",
    "- eliciting the LLM to produce text continuation that also exhibits step by step reasoning\n",
    "\n",
    "In the zero-shot setting, it simply involves appending\n",
    "> Let's think step by step\n",
    "\n",
    "to the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Chain of Thought Prompting</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/cot_step_by_step.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2201.11903.pdf\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's [use APE](https://arxiv.org/pdf/2211.01910.pdf#page=19) \n",
    "to find a zero-shot prompt appendage that improves upon \n",
    ">Let's think step by step\n",
    "\n",
    "That is: the instruction consists of\n",
    "- the task description\n",
    "- followed by a \"magic suffix\" (e.g., \"let's think step by step\")\n",
    "\n",
    "We want to find the best \"magic suffix\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors use the following template (where `INPUT` and `OUTPUT` are place-holders for an actual question and answer pair).\n",
    "\n",
    "        Instruction: Answer the following question\n",
    "        \n",
    "        Q: INPUT\n",
    "        A: Let's <INSERT> OUTPUT\n",
    "\n",
    "We are using forward-mode generation to get APE \n",
    "- to create a phrase that follows the `INPUT`\n",
    "- that begins with the word \"Let's\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "APE creates\n",
    "> Let’s work this out in a step by step way to be sure we have the right answer.\n",
    "\n",
    "and the author's demonstrate improved performance on several benchmarks.\n",
    "\n",
    "This is a nice demonstration of using an LLM to help craft better prompts to LLM's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
