{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**References**\n",
    "\n",
    "[InstructGPT paper](https://arxiv.org/pdf/2203.02155.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From Language Model to Helpful Assistant: Instruction following\n",
    "\n",
    "An LLM is trained in a text-completion task: predict the next token.\n",
    "\n",
    "Through the [Universal Model](NLP_Universal_Model.ipynb)\n",
    "we can transform many other tasks into instances of text-completion.\n",
    "\n",
    "The human user must \n",
    "- engineer a prompt\n",
    "- so that the  \"next token\" prediction\n",
    "- is the desired response\n",
    "\n",
    "For example, if you want an explanation of a topic\n",
    "- Don't prompt the LLM with \"Explain the Black Scholes pricing formula\"\n",
    "- Formulate the prompt in text-continuation form: \"The Black Scholes pricing formula states\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To make LLM's more human-friendly, \n",
    "they can be *fine-tuned* to exhibit *Instruction Following* behavior\n",
    "- the prompt is treated by the LLM as an *Instruction*:\n",
    "    - a request to perform a task\n",
    "    - rather than to predict the next token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover: we often want to constrain the response to be\n",
    "- helpful: follow the instructions\n",
    "- truthful: answers are honest\n",
    "- harmless: avoid bias or suggestions of dangerous behavior\n",
    "\n",
    "The \"LLM's\" we have become familiar with are, in fact\n",
    "- LLM's that have been fine-tuned to act as *Helpful Assistants*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Instruction following\n",
    "\n",
    "*Instruction following* behavior consists of 3 components\n",
    "- *Instruction*\n",
    "    - describing the task to accomplish\n",
    "- *Input* or *Context*\n",
    "    - the input to the task\n",
    "- *Response* or *Output*\n",
    "    - the expected response (output)\n",
    "    - given the Input\n",
    "    - given the Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example\n",
    "- Instruction: Tell me the word that is the opposite of the word that I input\n",
    "- Input: Stop\n",
    "- Response: Go\n",
    "\n",
    "The Context can be empty (pure instruction)\n",
    "- Instruction: Tell me a joke\n",
    "- Context:\n",
    "- Response: Why did the chicken cross the road ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's explore ! A training set for Instruction Following\n",
    "\n",
    "[Here](https://huggingface.co/datasets/databricks/databricks-dolly-15k/viewer/default/train)\n",
    "is a dataset created to Fine-Tune an LLM to become a Helpful Assistant (demonstrate Instruction Following Behavior)\n",
    "\n",
    "The examples are categorized as demonstrations of several types of tasks\n",
    "expected to be typical prompts,\n",
    ", for example\n",
    "- `closed_qa`: Question Answering, conditioned on a context\n",
    "- `open_qa`: Question Answering without a context\n",
    "- `summarization`: Summarize the Context\n",
    "- `information_extraction`: extract an Answer (from the Context) to the Question in the Instruction part\n",
    "- `classification`: what class does the Instruction indicate ?\n",
    "- `brainstorming`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Beyond Instruction Following\n",
    "- we often want to Fine-Tune the Helpful Assistant to be conversational.\n",
    "- the \"Chat\" in ChatGPT\n",
    "\n",
    "[Here](https://huggingface.co/datasets/OpenAssistant/oasst2/viewer/default/train?f%5Blang%5D%5Bvalue%5D=%27en%27&row=37) is a dataset mutli-turn \"conversations\" between \n",
    "the user (role: `prompter`) and the assistant (role: `assistant`)\n",
    "- chained together by `message_id` $\\rightarrow$ `parent_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LLM's struggle with Instruction Following \n",
    "\n",
    "The following examples illustrate the difference between\n",
    "- Text Completion behavior (left column, labeled `GPT-3 175B completion`)\n",
    "- and Instruction Following behavior (right column, labeled `InstructGPT 175B completion`)\n",
    "\n",
    "\n",
    "<img src=\"images/instructGPT_vs_GPT_output.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2203.02155.pdf#page=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the first example, the prompt (in French) is the Instruction\n",
    "\n",
    "    Write a short story about a frog who travels back in time to ancient Greece in French.\n",
    "\n",
    "without any Context.\n",
    "\n",
    "Even if you don't understand French, you can see the repetitive nature of the Text Completion response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the second example (explain a piece of code)\n",
    "- the Instruction is a request to explain some code\n",
    "- the Context is the code\n",
    "\n",
    "The response in the Text Completion behavior\n",
    "- is not even an answer to the request\n",
    "- the prompt appears to have been interpreted as the context for  of a multiple choice question\n",
    "    - it is **not wrong**, just not aligned with the user's intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fine-tuning an LLM to demonstrate Instruction Following behavior\n",
    "\n",
    "The way to extend a pre-trained model's behavior to encompass a new Target task is with Transfer Learning.\n",
    "\n",
    "The *Unsupervised Pre-Training + Supervised Fine-Tuning paradigm* is a type of Tranfer Learning\n",
    "- Adapting a Pre-Trained LLM\n",
    "- By Fine-Tuning with a small number of examples from the Target task\n",
    "\n",
    "To get a LLM to exhibit Instruction Following behavior, we need to have a dataset of examples\n",
    "that demonstrates Instruction Following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The examples in this dataset will be pairs or triples\n",
    "- an *Instruction* part\n",
    "    - tag \"Instruction: \"\n",
    "- an optional *Context* part\n",
    "    - tag \"Input: \"\n",
    "- the *Response* part: the target/label\n",
    "    - tag \"Output: \"\n",
    "\n",
    "For example\n",
    "- an Instruction part + Context part  \" $\\x$\n",
    "   \n",
    "   \n",
    "    Instruction: Given a word, find out its length and its number of vowels.\n",
    "    Input: Word = \"hello\"\n",
    "  \n",
    "- a Target Output part $\\y$\n",
    "    \n",
    "    Output: Length = 5, Number of vowels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) is a pre-trained GPT-3 that has been Fine-Tuned on \n",
    "a dataset that demonstrations of Instruction Following.\n",
    "\n",
    "The chart above demonstrating Instruction Following (i.e., the one with the prompt in French to write a story)\n",
    "- compares the Instruction following of pre-trained GPT-3\n",
    "- with a Fine-Tuned GPT-3\n",
    "\n",
    "The results are more satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where do the Instruction Following demonstration examples come from ?\n",
    "\n",
    "The demonstration examples for Instruction Following\n",
    "- were manually constructed by human labelers\n",
    "\n",
    "This is a very labor-intensive process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a separate module\n",
    "- we will describe several efforts\n",
    "- to *generate* training examples for the Instruction Following behavior\n",
    "- using an LLM !\n",
    "\n",
    "That is: we use a non-Instruction Following LLM\n",
    "- to create examples\n",
    "- on which to train an LLM to follow instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
