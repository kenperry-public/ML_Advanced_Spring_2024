{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**References**\n",
    "- [SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "- [Self-Alignment with Instruction Backtranslation](https://arxiv.org/pdf/2308.06259.pdf)\n",
    "- [Large Language Models can Self-Improve](https://arxiv.org/pdf/2210.11610.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using an LLM to generate Instruction Following examples\n",
    "\n",
    "In the module on [Instruction Following](LLM_Instruction_Following.ipynb)\n",
    "- we motivated the use of Fine-Tuning a LLM\n",
    "- to exhibit Instruction Following behavior\n",
    "\n",
    "Recall: an example of Instruction Following behavior is a triple, for example\n",
    "- Instruction: Tell me the word that is the opposite of the word that I input\n",
    "- Input: Stop\n",
    "- Response: Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Instruction describes the task to be accomplished\n",
    "- relationship between Input and Response\n",
    "- the Input/Response pair is an exemplar for this task\n",
    "\n",
    "In this module, we explore methods\n",
    "- to generate these fine-tuning examples\n",
    "- to improve examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using an LLM to generate Instruction Following examples\n",
    "\n",
    "[SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "\n",
    "Is there an alternative to the labor-intensity of constructing Instruction Following examples by human ?\n",
    "\n",
    "The idea of the [SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "is to use a Synthetic Data approach to constructing new examples of Instruction Following\n",
    "\n",
    "These examples are pairs of an Instruction part, and a Target Output part.\n",
    "\n",
    "The authors\n",
    "- use a *few-shot* learning approach to generate *synthetic* Instruction Following examples\n",
    "- augmenting a small number of human-constructed examples with the synthetic examples\n",
    "- using the augmented dataset to Fine Tune an LLM to better demonstrate Instruction Following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/selfinstruct_process.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The process involves multiple steps which we explain below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating the Instruction part of an Instruction-Output example\n",
    "\n",
    "The first step is to use few shot learning to generate synthetic Instructions\n",
    "- the Instruction part of an Instruction-Target Output example\n",
    "\n",
    "The synthetic Instructions are used to augment a small number of Instructions from the manually generated training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall: few-shot learning involves creating a prompt that is the concatenation of\n",
    "- a few exemplars ($\\langle \\x, \\y \\rangle$ pairs demonstration the task)\n",
    "- an example with no label: $\\x$\n",
    "\n",
    "Here is a template for a prompt demonstrating to GPT how to create a new Instruction \n",
    "\n",
    "<img src=\"images/selfinstruct_task_generation_prompts.png\" width=90%>\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating the Output part, given an Instruction\n",
    "\n",
    "The next step is to \n",
    "- choose an Instruction (called the *Target task*) from the augmented list of Instructions \n",
    "- prompt the LLM to generate the Target Output for the target task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The prompting for the output is achieved by few-shot learning.\n",
    "- Provide $k$ exemplars\n",
    "- Followed by a line consisting of \n",
    "    - The Instruction for the Target Task\n",
    "    -with the expectation that the LLM will create an Input/Output pair\n",
    "        - that obeys the Instruction\n",
    "        - correctly relates the Input and the Output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each exemplar is an Instruction following example for some other task.\n",
    "\n",
    "That is, it is a Instruction-Target Output pair.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For Classification tasks, the prompt might look like this\n",
    "\n",
    "    Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "    \n",
    "    Example 1\n",
    "    Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "    Class Label: mixed\n",
    "    \n",
    "    Example 2\n",
    "    Sentence: I had a great day today. The weather was beautiful and I spent time with friends.\n",
    "    Class label: Positive\n",
    "    \n",
    "    \n",
    "    Task: Tell me if the following email is a promotion email or not.\n",
    "    \n",
    "    Email: Check out our amazing new sale! Weâ€™ve got discounts on all of your favorite products.\n",
    "    Class label: Promotion\n",
    "\n",
    "    Email: We hope you are doing well. Let us know if you need any help.\n",
    "    Class label: Not Promotion\n",
    "    \n",
    "    Task: {instruction for the target task}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The last line above contains a place holder for the Instruction of the Target Task\n",
    "- the one for which we want the LLM to create a Target Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is an example of the template from the paper\n",
    "\n",
    "<img src=\"images/selfinstruct_generated_instances.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generating examples for Classification tasks\n",
    "\n",
    "Consider the an Instruction Following example for a Classification task\n",
    "\n",
    "    Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "    \n",
    "    Example 1\n",
    "    Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "    Class Label: mixed\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors found that the response generated by the LLM (e.g., Classification examples)\n",
    "- were examples whose Class Label's \n",
    "- were not well-distributed among all possible labels \n",
    "\n",
    "This was attributed to the *format* of the example called *Input-first*.\n",
    "- Additional Input\n",
    "- Precedes Target Output (e.g., `Class Label:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the format was changed to *output-first*\n",
    "- Target Output \n",
    "- precedes Additional Input\n",
    "\n",
    "the Classification examples generated had Class Label's that were less biased to one label\n",
    "\n",
    "\n",
    "     Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "\n",
    "     Example 1\n",
    "        Class Label: mixed\n",
    "        Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "        \n",
    "\n",
    "        Example 2\n",
    "        Class label: Positive\n",
    "        Sentence: I had a great day today. The weather was beautiful and I spent time with friends.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is an example of Prompt Engineering\n",
    "- In-context learning seems very sensitive to the format of prompts\n",
    "- There is a skill of engineering a prompt to elicit the desired behavior\n",
    "\n",
    "This feels similar to the idea behind Chain of Thought prompting\n",
    "- by presenting `Class Label` first\n",
    "- the model seems better conditioned to generate a less biased distribution of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Instruction Backtranslation\n",
    "\n",
    "*Backtranslation* is a method\n",
    "- to generate an instance of Instruction Following behavior\n",
    "$$\\langle\\x, \\y \\rangle =  \\langle \\text{Instruction}, \\text{Response} \\rangle$$\n",
    "- **given** only the $\\text{Response}$\n",
    "- using an LLM to create the $\\text{Instruction}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The essential idea is \n",
    "- given a *small* \"seed\"  of instruction/response pairs\n",
    "$$\\langle\\x, \\y \\rangle =  \\langle \\text{Instruction}, \\text{Response} \\rangle$$\n",
    "- create an inverse dataset of response/instruction pairs by reversing the features and targets\n",
    "$$\\langle\\y, \\x \\rangle =  \\langle  \\text{Response}, \\text{Instruction} \\rangle$$\n",
    "- fine-tune an LLM to predict $\\text{Instruction}$ from $\\text{Response}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Fine-Tuned model can be used to\n",
    "- create a task description (Instruction) describing the task\n",
    "- given demonstrations (Response) of a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The results of using the Fine-Tuned model to create new examples\n",
    "- can be used as synthetic examples\n",
    "- to augment the seed examples\n",
    "\n",
    "One can then iteratively augment the examples further\n",
    "- by using Step $i$ augmented data\n",
    "- as the \"seed\" to create Step $(i+1)$ augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the workflow:\n",
    "\n",
    "<table>\n",
    "    <center><strong>Instruction Backtranslation</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/instruction_backtranslation.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2308.06259.pdf#page=2\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting the best synthetic examples for augmentation\n",
    "\n",
    "The quality of the synthetic examples created at each step may not be uniformly high.\n",
    "\n",
    "It would be desirable to select only the best examples to use in augmenting the seed examples of each Step.\n",
    "\n",
    "How can we rate the quality of a synthetic example ?\n",
    "\n",
    "Ask the LLM to do it for you ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following prompt requests that the LLM evaluate the\n",
    "synthetic example using a rating scale of $1$ (low quality) to $5$ (high quality)\n",
    "\n",
    "<table>\n",
    "    <center><strong>Instruction Backtranslation Curation</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/instruction_backtranslation_curating.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2308.06259.pdf#page=4\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic Prompt Engineering (APE)\n",
    "\n",
    "The Automatic Prompt Engineer (APE) is a system to *improve* upon prompts\n",
    "- given a prompt\n",
    "- APE will create a prompt that is *more effective*\n",
    "\n",
    "It uses an LLM\n",
    "- to create variations of the given prompt\n",
    "- evaluate which variation is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One use of APE is\n",
    "- to create an *instruction* describing a task\n",
    "- given exemplars for a task (the input/output mapping for the task)\n",
    "\n",
    "So, we might use APE to create synthetic examples for Instruction Following\n",
    "- conditional on having only instances of input/output pairs for the task\n",
    "\n",
    "Let visit the module: [APE](Prompt_Engineering_APE.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Related work: Self-improvement\n",
    "\n",
    "The methods illustrated use a LLM to help improve future iterations of the LLM.\n",
    "\n",
    "This is called *self improvement*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A related [paper](https://arxiv.org/pdf/2210.11610.pdf) adds some interesting ideas.\n",
    "\n",
    "The first idea relates to the construction of the exemplars\n",
    "- use Chain of Though (CoT) exemplars as demonstrations of the task\n",
    "    - for example generation\n",
    "\n",
    "CoT prompts have been shown to increase the likelihood of generating a correct response\n",
    "- by explicitly asking for \"step by step\" reasoning to be included\n",
    "- rather than just outputting the \"answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But even with step by step reasoning, a wrong answer may be output.\n",
    "\n",
    "The other idea adapted by the authors is *multiple reasoning paths*\n",
    "- sample multiple outputs for each question\n",
    "- extract the \"answer\" part (i.e., ignore the step by step part) from the output\n",
    "- the answer that occurs most frequently among the multiple answers is deemed more likely to be correct\n",
    "\n",
    "The answer deemed to be correct\n",
    "- is then used as a training example\n",
    "- to improve the model's future behavior on similar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
