{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb\n",
    "%run beautify_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wasserstein GAN: Motivation\n",
    "\n",
    "[paper](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "\n",
    "To summarize what we have learned about standard GANs:\n",
    "- Adversarial Training minimizes the Jensen Shannon Distance between $\\pmodel$ and $\\pdata$\n",
    "- They have the reputation for being difficult to train\n",
    "    - A Discriminator that is too good, too soon inhibits the ability of the Generator to learn to generate\n",
    "    - The Generator may \"mode collapse\" and not produce a variety of outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The *Wasserstein GAN (WGAN)* is a pair of Neural Networks NN:\n",
    "- the Generator\n",
    "- the Discriminator\n",
    "    - technically, this is a \"critic\"\n",
    "        - rather than producing a probability of \"Real\"\n",
    "        - it produces a \"score\" measuring how real the input is\n",
    "            - larger negative: more real\n",
    "            - larger positive: less real\n",
    "\n",
    "The pair is trained to minimize an *approximation* of\n",
    "$$\n",
    "\\mathbb{W}( \\pdata, \\pmodel )\n",
    "$$\n",
    "\n",
    "where $\\mathbb{W}$ is the *Wasserstein Distance*, also know as the *Earth Move Distance (EMD)* measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Earth Move Distance (EMD)\n",
    "\n",
    "**Aside**\n",
    "\n",
    "You need some knowledge of Measure Theory to understand the math.\n",
    "\n",
    "In the absence, there are two good blogs I recommend in order to get a flavor\n",
    "- [Sorta Insightful](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)\n",
    "- [Wen](https://arxiv.org/pdf/1904.08994.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Like the KL and Jensen-Shannon Distances, the EMD is a measure of the difference between two distributions.\n",
    "$\\pdata$ and $\\pmodel$.\n",
    "\n",
    "It has an intuitive explanation\n",
    "> The minimum amount of \"work\" involved in moving probability mass between the two distributions in order to make them identical\n",
    "\n",
    "\"Work\" means: the product of \n",
    "- the quantity $\\gamma(x,y)$ of the mass moved from $x$ to $y$ \n",
    "- and the distance $\\| x -y \\|$ it is moved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can easily illustrate with two discrete distributions (example from [Wen](https://arxiv.org/pdf/1904.08994.pdf)\n",
    "\n",
    "Let $P, Q$ be the two distributions, represented as vectors since there are discrete and measured over the same indices.\n",
    "\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "P & = & [ 3, 2, 1, 4 ] \\\\\n",
    "Q & = & [ 1, 2, 4, 3 ]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$P_i$ (resp., $Q_i$) is the probability as $i$ in each of the distributions, for $1 \\le i \\le 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For illustration, we will move \n",
    "- a quantity $\\delta_i$ of probability in $P$ between adjacent indices $(i-1)$ and $i$\n",
    "- in order to make $P_i = Q_i$ ($Q_i$ remains fixed)\n",
    "- The distance is 1 (and hence work is equal to quantity moved).\n",
    "\n",
    "We can define $\\delta_i$ recursively:\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\delta_0 & = & 0 \\\\\n",
    "\\delta_{i+1} & = & \\delta_i + P_i - Q_i \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is, the amount $\\delta_{i+1}$ moved from $P_i$ in order to make $P_i = Q_i$ is\n",
    "- the difference $(P_i - Q_i)$ between original value of $P_i$ and $Q_i$\n",
    "- plus the additional quantity $\\delta_i$ that was moved into $P_i$\n",
    "\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\delta_0 & = & 0 \\\\\n",
    "\\delta_1 & = & 0 & + & 3 & - & 1 & = & 2 \\\\\n",
    "\\delta_2 & = & 2 & + & 2 & - & 2 & = & 2 \\\\\n",
    "\\delta_3 & = & 2 & + & 1 & - & 4 & = & -1 \\\\\n",
    "\\delta_4 & = & -1 & + & 4 & - & 3 & = & 0 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Work is positive so taking absolute values\n",
    "$$\n",
    "\\mathbb{W}(P,Q) = \\sum_{i=1}^4 { 1 * | \\delta_i | } = 5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For continuous distributions\n",
    "\n",
    "$$\n",
    "\\mathbb{W}(\\pdata, \\pmodel) = \\inf_{\\gamma \\in \\Pi(\\pdata, \\pmodel)} { \\mathbb{E}_{(x,y) \\sim \\gamma} \\| x - y \\| }\n",
    "$$\n",
    "where\n",
    "- $\\Pi(\\pdata, \\pmodel)$ are the set of possible joint distributions with marginal $\\pdata$ and $\\pmodel$\n",
    "- $\\gamma$ is a quantity to move from $x$ to $y$ (for all $x, y$)\n",
    "    - distance between $x$ and $y$ is $\\| x - y \\|$\n",
    "- $\\inf$ is the infimum (Greatest Lower Bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Approximation of $\\mathbb{W}(\\pdata, \\pmodel)$\n",
    "\n",
    "**Warning: the math is stated without much explanation**\n",
    "\n",
    "The infimum is intractable (or at least: not practical to compute).\n",
    "\n",
    "Equation 2 in the paper states that for certain functions $f$, the distance is also equal to \n",
    "\n",
    "$$\n",
    "\\mathbb{W}(\\pdata, \\pmodel) = \\inf_{\\|f\\|_2 \\le 1} { \\mathbb{E}_{x \\sim \\pdata}  f(x )  \\, - \\, \\mathbb{E}_{x \\sim \\pmodel}  f(x )}\n",
    "$$\n",
    "\n",
    "One can look at $f$ as a \"score\" of $x$ being \"Real\" (not fake) where\n",
    "- a high negative score is a highly confident  \"Real\"\n",
    "- a high positive score is a highly confident \"Fake\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The goal is \n",
    "- for function $f$ to create a *large spread* between scores of Real and Fake.\n",
    "- for function $f$ to be *approximated* by the Discriminator $D_\\Theta$ with weights $\\Theta_D$\n",
    "\n",
    "\n",
    "Under certain conditions on $f$, finding $\\mathbb{W}$ is equivalent to solving\n",
    "\n",
    "$$\n",
    "\\max{\\Theta_D \\in \\mathcal{W} } { \\mathbb{E}_{x \\sim \\pdata}  D_{\\Theta_D} (x)  \\, - \\, \\mathbb{E}_{x \\sim \\pmodel}  D_{\\Theta_D} (x)}\n",
    "$$\n",
    "where $\\mathcal{W}$ is a \"compact\" space of possible weights\n",
    "\n",
    "Since the Discriminator no longer produces binary categorical values, it is more appropriate to call it a *Critic*.\n",
    "\n",
    "That is: we solve for Critic weights such that the scores it produces have a large spread between Real and Fake.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But: what does this mean ?\n",
    "\n",
    "For those (like me) struggling with the math, here are the implications from a practical perspective\n",
    "- Scores for true Real is negative, for Fake is positive\n",
    "- $\\loss_G$ will implement: minimize (make most negative) the score assigned to Fakes\n",
    "- $\\loss_D$ will implement: \"maximize the spread of scores between Real and Fake\"\n",
    "    - by minimizing the sum of \n",
    "        - sum of scores for Real examples\n",
    "        - minus sum of scores for Fake examples (i.e., Discriminator goal is for Fakes to have positive scores)\n",
    "- \"Compact\" $\\Theta_D$ will be achieved by clipping\n",
    "    - restricting elements of $\\Theta_D$ to a small numerical range\n",
    "    - by clipping the weights after a gradient update step for $D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $\\loss_D$ will dispense with the $\\log$ since the Discriminator produces scores rather than probabilities\n",
    "    - we see terms $D(\\x^\\ip)$ and $1 - D(\\x^\\ip) $\n",
    "    - rather than $\\log D(\\x^\\ip)$ and $1 - \\log D(\\x^\\ip)$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we visit the code, we will see these elements in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Did I really need to change to EMD ?\n",
    "\n",
    "The Wasserstein GAN avoids many of the problems associated with the plain GAN.\n",
    "\n",
    "To some extent, this is due to replacing the Discriminator with a Critic\n",
    "- unbounded scores in the WGAN versus bounded probabilities in the plain GAN\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- There are mathematical problems with Expectation Maximization (KL distance) and Jensen-Shannon (JS)distance\n",
    "    - the terms $\\log(\\pmodel(\\x))$ and $\\log(\\pdata(\\x))$ appear\n",
    "    - if $\\pdata$ and $\\pmodel$ don't completely overlap (a possibility especially early in training)\n",
    "        - we take logs of $0$, which is infinite (negative)\n",
    "    - No such problem with EMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- No vanishing gradients with EMD\n",
    "    - with KL and JS distance the true derivative goes to 0\n",
    "    - no such problem with EMD\n",
    "        - The Critic's scores are not bounded, so can't saturate\n",
    "    - Thus: we can train the Discriminator to convergence immediately\n",
    "        - No danger of being too good too soon\n",
    "        - When we see code we will observe\n",
    "            - The number of steps of Discriminator update is a multiple of the number of steps of Generator  update\n",
    "- No mode collapse with EMD\n",
    "    - with a fixed Discriminator (classifier), the Generator in a plain GAN will seek out examples with highest probability of being mis-classified as Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
